# 論文紹介"Optimal control of reaching includes kinematic constraints"

## 文献情報

### 著者: Michael Mistry,Evangelos Theodorou,Stefan Schaal,and Mitsuo Kawato

### 雑誌名: Journal of neurophysiology

### 巻・号:110.1

### 出版年:2013

## Keyword
- 確率的最適制御理論（stochastic optimal control theory）: ノイズなどの不確かさがある場合にも運動や行動をできるだけうまく（最適に）コントロールするための理論
- 感覚運動系 (Sensorimotor Systems): 目で見て（感覚）、手で掴む（運動）といった、感覚と運動を連携させる脳と体のシステム全体
- LQGフレームワーク: SOCの中でも特に扱いやすい、基本的なモデル
  - L (Linear / 線形): 物の動きを単純な線形方程式で記述します。
  - Q (Quadratic / 二次): コスト（誤差やエネルギー）を二乗の形で計算。
  - G (Gaussian / ガウス): ノイズが釣鐘型の正規分布（ガウス分布）に従うと仮定

## 今回の論文紹介の流れ
- 実験をしてみた⇨予想と違う結果になった⇨この意外な結果を数学的な枠組みでうまくモデル化することができた⇨一緒の論文にしよう
- 実験について話した後、時間があればモデルについて説明

## イントロダクション
- 「感覚運動(感覚と運動の機能が組み合わさった、もしくは相互作用している状態:目で見て（感覚）、手で掴む（運動）)の制御・計画・実行の背後には最適化が働いている」という考え方は、長い間提案されてきた
- 最適化では、コスト関数を最小化することで、可能な限り最良の移動や制御戦略を導き出そうとしている（ex: ジャーク最小化、トルク変化、分散など）
- 最近のモデルでは、確率的最適制御の枠組みを用いることで、人の動作がどのように生まれるのかが理論的に示されている（ex:動作中の運動指令の合計(筋肉への指令（力や速度など）の総量)と、動作終了時の位置誤差を最小化するような制御戦略によって、リーチング動作を説明）
- こうしたモデルで使われるコスト関数には、通常「手が目標までどんな軌道を通るべきか」といった運動学的な制約（たとえば軌道形状の指定）が含まれていない
- 中枢神経系（CNS）は、リーチングの成功において手の軌道そのものを必ずしも重視しない可能性があると示唆
- 考慮すべき重要な点は、リーチング動作の学習過程ではCNSがどのように適応戦略を選んでいるのかという点である
- 例えば、回転する部屋や外力を加えるロボットなどの新しい力学環境でリーチングを学ぶとき、CNSはどのような要因に基づいて適応戦略を決めているのかは明確ではない
- もしこの学習過程が最適化に基づいて進むのであれば、試行のたびにコスト（費用関数）を削減していくことが、適応の最も根本的な動機であると考えられる
- このように適応とは再最適化であるという概念に基づいて、この研究では人の適応戦略を調査する。
- 目的：リーチング中に加速度に依存する一時的な外乱を加えた際に、ヒトはどのような運動戦略でそれに適応するのかを明らかにする
- （時間があれば）特に以下の３つの相反する要求の間で人がどのようにトレードオフしているかを調べる
    - ターゲットへの正確な到達
    - 運動エネルギー消費の少なさ
    - 運動学的不変性（どのような条件でも似たような軌道や速度パターンで動く傾向）


## 研究手法
- タスク内容
  - 外乱を反映した力場でのリーチング動作の実験
  - 被験者:合計16人の健康な右利きの被験者（20〜32歳、男性14人、女性2人）
  - 体性感覚（身体の表面や内部から得られる感覚）のフィードバックのみにするため、被験者には試行の最後に手の最終位置を見せるだけで、動かしている最中の手の軌道などは見せないようにしている
  - 式(1)の説明
    - 1 項目: 進行方向に加速すればするほど、x軸の正の方向に力が加わる。減速するとx軸の負の方向に力が加わる
    - 2 項目: x軸方向への力に対して、その力を減衰させる方向の力を与える
    - リーチングの前半は手がx軸の正の方向に手先が逸れて、後半には手が戻る方向に力が加わる（図 1）
    - 実験で加える力の強さ（ゲイン）は、被験者の手が一度大きくコースから外れた後、最終的に目標に戻れるくらいの強さに、予備研究を通じて調整された
  - 図２の説明（ATR planar force manipulandum (PFM)）
    - ２次元平面
    - 自由度は２（肩と肘）
    - 被験者は椅子に座り、背中を椅子に当てるために肩のハーネスで縛られている
    - 手首は動かないように固定し、装置のハンドルに接続
    - the tabletop covers（布？）で見えなくしている
    - 天井に取り付けられたプロジェクターで手先の初期位置と目標地点と運動終了時に手先の位置のフィードバックをテーブル上に表示
    - 速度、加速度などのデータは500 hz で記録
    - ハンドルに加えた力はPFMという0.06 N という細かい単位まで測れる力学センサー(Nitta no. 328)で測定
  - 具体的な実験内容
    - 初期位置はターゲットは半径 2.0 cm の円、ターゲットは半径 2.5 cm の円
    - 距離 25 cm で、800 ms ± 150 ms で到達するように求められている
    - 手先を初期位置に置くために、手の位置の視覚的なフィードバック（点で示される）が提供されるが、開始位置から4cm以内のみであり、被験者が開始時に手を適切に配置できるようにするためにのみ提供される
    - 開始位置の円に入ると、視覚的なフィードバックが削除され、試行の開始を示すために3回連続したビープ音が鳴る
    - 被験者は、3回のビープ音の終了後に動きを開始し、指定された時間内でターゲットで停止するように求められる
    - 手の動かし方や、ターゲットまでどの軌道を取るべきかなどの指示は与えられていない
    - トライアルの最後に最後の手の位置を示す単一の点が表示され、その試行が成功か失敗かを知らされる
    - 成功は、指定された時間枠の間にターゲットサークル内に到着した手と停止によって定義
    - 失敗した場合、手が遅すぎたり、早すぎたり、ターゲットから外れたりしたかどうかが被験者に教えられる
    - 各被験者は２つの条件のいずれかで実験を行った
    - 実験A
      - null field（力場による外乱がない環境）での初期訓練の後、最初からforce field（式 1での環境）での実験
      - 被験者が初期の訓練時とは違った大きく曲がる軌道に気づき、その後運動戦略を適応させるために意識的な努力をするのではないか
      - 6人の被験者（男性5人、女性1人）
      - 5つのトライアルブロックでテスト、各ブロックの間に5分間の休憩
      - ブロック1では、null field で 70 回成功させる
      - ブロック2では、null field で 30 回成功した後、10 回のランダムキャッチトライアル（被験者には知らせずにforce fieldに切り替わる）を含む 80 回の試行を実行
      - ブロック3とブロック4は、force fieldで 60 回の試行を成功させる
      - ブロック5は、force fieldで 30 回成功した後、10 回のランダムキャッチトライアル（被験者には知らせずにnull fieldに切り替わる）を含む 80 回の試行を実行
    - 実験B
      - 意識的な適応の影響を最小限に抑えるため、力場の強さを試行ごとに徐々に増加させる
      - 合計10人の被験者（男性9人、女性1人）
      - 4つのトライアルブロックでテスト、各ブロックの間に5分間の休憩
      - ブロック1では、null field で 70 回成功させる
      - ブロック2では、null field で 30 回成功した後、18回の試行で力場による外乱を試行ごとに直線的に上昇させ、force fieldで 40 回の試行を成功させる
      - ブロック3は、force fieldで 70 回の試行を成功させる
      - ブロック4は、force fieldで 40 回成功した後、10 回のランダムキャッチトライアル（被験者には知らせずにnull fieldに切り替わる）を含む 80 回の試行を実行

## データ分析
- 軌道の曲率（直線からの誤差）を計算
  - 初期地点と目標地点を結ぶ直線からサンプリングした軌道の全ての点に対して平均垂直距離を計算
  - 初期地点と目標地点を結ぶ直線に対して、軌道の大部分が右側にある場合は正の値を与え、それ以外の場合は負の値
  - 運動の開始は手先の速度がピークに達する前の時刻という条件下で、手先の速度が 0.05 m/s である時刻
  - 運動の終了は手先の速度がピークに達した後の時刻という条件下で、手先の速度が 0.05 m/s になった時刻

## 結果
- 図４の説明
  - 実験AとBのそれぞれの被験者の軌道の平均
  - Baselineは null field での最後の15試行の軌道平均（ブロック２の最初）
  - final forceはforce fieldでの最後の15試行の軌道平均
  - before effectsはランダムキャッチトライアルのnull fieldでの10試行の軌道平均
  - after effectsはランダムキャッチトライアルのforce fieldでの10試行の軌道平均
  - 実験Aの細い実線はブロック３での環境の学習に際した10試行ごとの軌道の平均
  - 実験Bの細い実線はブロック2での徐々に力場による外乱の強さを増やしていった時の最初の10試行と最後の10試行の平均
  - 実験Bの細い実線はブロック３のforce fieldでの最初の10回とその次の10回の平均
  - 力場に適応する前は手がまず右に押されてから、目標方向に戻るような動きになる（before effects）
  - 力場に適応した後は実験Aでは軌道をベースラインに回復し、実験Bではもともとのベースラインを維持する傾向
  - after effectsは力場による外乱に対する予測的な内部モデルの形成（脳が外乱がある前提で動こうとしてしまう）
- 図５の説明
  - 力場トレーニング中に軌道の曲がり具合（curvature）がどう変化するか
  - A：ブロック3（＝力場トレーニングの最初のブロック）における、試行ごとの平均学習曲線
  - B:実験Bのブロック2における平均学習曲線.
  - 灰色の破線は力場による外乱がゼロから徐々に上がっていることを示す
  - グラフのy軸は、試行の開始点からターゲットまでを結ぶ直線からの平均距離
  - ベースラインは破線
  - 太線は15試行分ごとの学習曲線の移動平均
- 図６の説明
  - ターゲットに垂直な方向（＝力場の外乱方向）に加わった力を、操作ハンドルに取り付けられた力センサで記録したもの
  - averaged:実験Aの場合の６人の平均
  - individual:実験Aの1人の被験者の個々の試行
  - Baselineはnull fieldでの最後の15試行の平均（ブロック２の最初）
  - final forceはforce fieldでの最後の15試行の平均
  - before effectsはランダムキャッチトライアルのnull fieldでの10試行の平均
  - 動きの初期で、左向き（負方向）の大きな力が見られる⇨被験者は力場によって右に押されるのを打ち消すように、左に力を加えている
## まとめ
- 中央神経系（CNS）がどのような戦略で運動を適応させるかを調べた。
- 人は「直線的な動き」を強く好む傾向がある⇨位置ずれ（運動学的エラー）は運動学習に関係ないという仮説は否定される
- （時間に余裕があれば）人間の運動は、①「なるべくまっすぐ動きたい」②「正確にゴールしたい」③「筋力を節約したい」という3つの目標のバランスを取る戦略であると主張


## 時間に余裕があれば
 - SOC（ノイズがある中で、ある目的にとって最適な動きを計算するための数学的な枠組み）について
    - 生体の感覚運動系 (Sensorimotor Systems)の推定と制御をモデル化するための強力なツール
    - 式２の説明
      - SOCの LQGフレームワーク（SOCの中でも特に扱いやすい基本的なモデル）
      - $\boldsymbol{x}_t$:状態ベクトル（２次元座標における質点の位置や速度など）
      - $\boldsymbol{u}_t$:制御入力ベクトル（これくらい力をだせという筋肉への運動指令）
      - $i$:各筋肉のインデックス、$c$:制御している筋肉の総数
      - $A$:状態遷移行列（物理法則を表現する行列）
      - $B$:制御入力行列（筋肉への指令が腕の状態にどう影響を与えるかを表現する行列（状態ベクトルの次数×制御入力ベクトルの次数）
      - $C_i$:指令に対するノイズのスケーリング行列(状態ベクトルの次数×制御入力ベクトルの次数)（筋肉によるノイズの乗りやすさを表現）
      - $\xi_t$:一定のランダムな平均0のガウシアンノイズ
    - 式 3 の説明
      - 人は状態ベクトルを部分的に観測可能であると仮定した時の感覚フィードバック
      - $\boldsymbol{y}_t$:観測値
      - $H$:観測行列（状態全体のうち、どの部分を観測できるかを表す行列）
      - $\omega_t$:平均0のガウシアンノイズ
    - 式 4 の説明
      - 各時刻 t において、状態ベクトル $\boldsymbol{x}_t$ と制御入力$\boldsymbol{u}_t$に対する2次形式のコスト関数
      - $Q_t$:半正定値行列（固有値が0以上）
      - $R$:正定値行列(固有値が全て正)
    - 式 5,6 の説明
      - Todorovの最適な制御器と状態推定器
      - $\boldsymbol{\hat{x}}_t$:時刻 t の状態の推定値
      - $L_t$:最適な制御ゲイン（状態の推定値に対して、どのような制御入力にするかを決める重みみたいなもの）、$K_t$:最適な推定ゲイン（実際の観測と推定観測の差分を使って、状態の推定を更新するときの調整の強さを決める重み）
      - 動的計画法で反復計算される
    - 式 7 の説明
      - 人の腕を表現した10次元の状態ベクトル
      - $\boldsymbol{P}_t, \boldsymbol{V}_t$:２次元座標における質点位置と速度
      - $\boldsymbol{f}_t$:２次元の筋肉の出力
      - $\boldsymbol{g}_t$:２次元の筋肉の活動
      - ${\boldsymbol{P}_t}^*$:２次元座標における目標地点の位置
    - 式 8 の説明
      - 点質量の位置
    - 式 9 の説明
      - 点質量の速度
      - $D$:外力行列（力場による外乱）
    - 式 10 の説明
      - ２次元の筋肉の出力
      - $\tau_2$:筋出力の時定数
      - １項目はdtによる減衰
    - 式 11 の説明
      - ２次元の筋肉の活動
      - $\tau_1$:筋活動の時定数
      - $\sigma_c$:各筋肉によるノイズをスケーリングするための定数
      - １項目はdtによる減衰
      - ２項目は制御入力ベクトルに対してノイズをのせている
    - 式 12 の説明
      - 今回の場合の外力
      - $\beta$:フィールド強度を0から1にスケーリングするためのパラメータ(0:null field, 1:force field)
    - 式 13 の説明
      - 2次のコスト関数
      - $w_{p,v,f}$:それぞれ位置、速度、力に対する重み
      - $t_{f}$:指定された到達時間
      - １項目は終端地点と目標地点との差分の2乗
      - ４項目は制御入力の総和
      - 式 14 はそれをコンパクトにまとめたもの
    - 式 15 の説明
      - ヒトは外力を完全に把握していない
      - $\hat{D}$:推定外力行列
      - $\alpha$:0~1の値を取る
    - 式 16 の説明
      - コスト関数を望ましい方向を含むように拡張させるための行列
      - $\boldsymbol{d}$:望ましい方向を表す単位ベクトル$\boldsymbol{d}$で表せられる行列
    - 式 17 の説明
      - 拡張されたコスト関数
      - 運動全体にわたって運動学的制約を課す必要がないことを示すために、指数的に減衰する項（運動前半の補正に使われる）
      - $\boldsymbol{d}=[0 1]$で定義（運動開始時の目標地点への方向を指すベクトル）
    - 式 18 の説明
      - $\boldsymbol{d}=[0 1]$で簡略化されたコスト関数
  - ベースライン（力場なし）と完全適応後（力場に慣れた後）では、ベル型の速度プロファイルと目標到達がうまくいくようにパラメータを調整した。

  - 図４の説明
    - 実験AとBのそれぞれの被験者の軌道の平均
    -  Baselineはnull fieldでの最後の15試行の軌道平均（ブロック２の最初）
    - final forceはforce fieldでの最後の15試行の軌道平均
    - before effectsはランダムキャッチトライアルのnull fieldでの10試行の軌道平均
    - after effectsはランダムキャッチトライアルのforce fieldでの10試行の軌道平均
    - 実験Aの細い実線はブロック３での環境の学習に際した10試行ごとの軌道の平均
    - 実験Bの細い実線はブロック2での徐々に力場による外乱の強さを増やしていった時の最初の10試行と最後の10試行の平均
    - 実験Bの細い実線はブロック３のforce fieldでの最初の10回とその次の10回の平均
    - 力場に適応する前は手がまず右に押されてから、目標方向に戻るような動きになる（before effects）
    - 力場に適応した後は実験Aでは軌道をベースラインに回復し、実験Bではもともとのベースラインを維持する傾向
    - after effectsは力場による外乱に対する予測的な内部モデルの形成（脳が外乱がある前提で動こうとしてしまう）
    - SIM.nd：非方向性コスト関数を用いた最適制御のシミュレーション
    - SIM.d : 方向性コスト関数を用いたシミュレーション
    - before effectsは$\alpha=0$
    - A.SIM
      - 細い線はそれぞれ$\alpha$を0.25, 0.5, 0.75にしたときのもの
      - final forceは$\alpha=1.0$
    - B.SIM
      - 細い線はそれぞれ$\alpha$を0.25, 0.5, 0.75、$\beta$を0.25, 0.5, 0.75にしたときのもの
      - final forceは$\beta=1.0$、$\alpha=1.0$
    - どちらのコスト関数でも、学習前（Before Effect）の軌道は、右に曲がりながら、目標より左に外れる
    - 実験Aで非方向性コストを使うと、外側に膨らむように適応し、軌道の曲がりは増加
    - 方向性コストを使うと、内側に向かって適応し、軌道の曲がりは減少
    - 実験Bでも、力場の強さが徐々に増すと、非方向性コストでは軌道の曲がりも徐々に増加
    - 方向性コストでは軌道はほとんど変化しない
  - 図６の説明
    - ターゲットに垂直な方向（＝力場の外乱方向）に加わった力を、操作ハンドルに取り付けられた力センサで記録したもの
    - averaged:実験Aの場合の６人の平均
    - individual:実験Aの1人の被験者の個々の試行
    - Baselineはnull fieldでの最後の15試行の平均（ブロック２の最初）
    - final forceはforce fieldでの最後の15試行の平均
    - before effectsはランダムキャッチトライアルのnull fieldでの10試行の平均
    - 動きの初期で、左向き（負方向）の大きな力が見られる⇨被験者は力場によって右に押されるのを打ち消すように、左に力を加えている 
    - nondirectional cost:抵抗がなく、押されるままになる⇨非人間的
    - directional cost：被験者と同様に力場に逆らう力を出す⇨より現実的・人間的
  - 図７の説明
    - 最適制御モデルのコスト関数に方向の制約を入れると、動作の初期段階でより早く・力強く補正するようになる。つまり、剛性と減衰が増加するのと同じ効果が得られる
  - 図８の説明
    - 最適制御器は元の質量を仮定して設計
    - 質量を変化させた時の頑健性を調べる
